# -*- coding: utf-8 -*-
"""TsunamiSis3.pynb

Automatically generated by Colab.


Original file is located at
    https://colab.research.google.com/drive/132J0UkonnZl4dA1bhBK-Heo2WvABYfFp
"""

import pandas as pd

df = pd.read_csv('tsunami_data.csv')

df.head()

columns_to_drop = ['DEATHS_TOTAL_DESCRIPTION', 'URL', 'HOUSES_TOTAL_DESCRIPTION',
                   'DAMAGE_TOTAL_DESCRIPTION', 'EQ_DEPTH', 'DAY', 'HOUR', 'MINUTE']

df.drop(columns=columns_to_drop, inplace=True)

df.head()

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score
import numpy as np

# Crear categorías de riesgo basadas en 'TS_INTENSITY'
# Por ejemplo:
# 0-1 = Bajo, 2-3 = Medio, 4+ = Alto

def categorize_risk(intensity):
    if intensity <= 1:
        return 'Bajo'
    elif 1 < intensity <= 3:
        return 'Medio'
    else:
        return 'Alto'

# Aplicar la función a la columna 'TS_INTENSITY' para crear una nueva columna 'Risk_Level'
df['Risk_Level'] = df['TS_INTENSITY'].apply(categorize_risk)

# Seleccionar las características (X) y la variable de destino (y)
X = df[['YEAR', 'LATITUDE', 'LONGITUDE', 'EQ_MAGNITUDE']]  # Puedes ajustar las columnas si deseas
y = df['Risk_Level']

# Dividir en conjuntos de entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Crear el modelo Random Forest
clf = RandomForestClassifier(n_estimators=100, random_state=42)

# Entrenar el modelo
clf.fit(X_train, y_train)

# Realizar predicciones en el conjunto de prueba
y_pred = clf.predict(X_test)

# Calcular precisión y mostrar reporte de clasificación
print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))


"""NO TOCAR EL USER AGENT"""

from geopy.geocoders import Nominatim
from geopy.exc import GeocoderTimedOut

# Crear un geo-localizador - NO TOCAR EL USER AGENT
geolocator = Nominatim(user_agent="miAplicacionDeGeolocalizacion")


# Función para obtener el país usando latitud y longitud
def get_country(lat, lon):
    try:
        location = geolocator.reverse((lat, lon), language="en", timeout=10)
        if location and location.raw.get('address', {}).get('country'):
            return location.raw['address']['country']
        else:
            return "Unknown"
    except GeocoderTimedOut:
        return "Service Timeout"

"""PRUEBA DE PREDICCION - LUEGO QUE LOS INPUTS ESTEN EN LA WEB

"""

# DATOS DE PRUEBA
new_data_batch = [
    [2024, 34.05, -118.25, 7.1],
    [2023, 35.68, 139.69, 2.3],
    [2022, 1.35, 103.82, 8.3]
]

# Realizar predicciones de riesgo
predicted_risks = clf.predict([data[:4] for data in new_data_batch])

# Mostrar los resultados junto con el país
for i, data in enumerate(new_data_batch):
    year, lat, lon, magnitude = data
    risk = predicted_risks[i]
    country = get_country(lat, lon)
    print(f"Evento {i+1}, Nivel de riesgo predicho: {risk}, País: {country}")

import matplotlib.pyplot as plt
import seaborn as sns

# Visualización de la distribución de los niveles de riesgo
plt.figure(figsize=(8, 6))
sns.countplot(data=df, x='Risk_Level', palette='viridis')
plt.title('Distribución de los Niveles de Riesgo de Tsunami')
plt.xlabel('Nivel de Riesgo')
plt.ylabel('Cantidad de Eventos')
plt.show()

# Visualización de la relación entre Magnitud del Terremoto y el Nivel de Riesgo
plt.figure(figsize=(8, 6))
sns.boxplot(data=df, x='Risk_Level', y='EQ_MAGNITUDE', palette='coolwarm')
plt.title('Relación entre Magnitud del Terremoto y Nivel de Riesgo')
plt.xlabel('Nivel de Riesgo')
plt.ylabel('Magnitud del Terremoto')
plt.show()

# Visualización de la relación entre Latitud, Longitud y Nivel de Riesgo
plt.figure(figsize=(8, 6))
sns.scatterplot(data=df, x='LATITUDE', y='LONGITUDE', hue='Risk_Level', palette='Set1')
plt.title('Relación entre Latitud, Longitud y Nivel de Riesgo')
plt.xlabel('Latitud')
plt.ylabel('Longitud')
plt.legend(title='Nivel de Riesgo')
plt.show()

# Mapa de calor de la matriz de correlación
plt.figure(figsize=(10, 8))
corr = df[['YEAR', 'LATITUDE', 'LONGITUDE', 'EQ_MAGNITUDE']].corr()
sns.heatmap(corr, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)
plt.title('Mapa de Calor de la Matriz de Correlación')
plt.show()

# Si quieres ver la importancia de las características para el modelo de Random Forest
importances = clf.feature_importances_
features = ['YEAR', 'LATITUDE', 'LONGITUDE', 'EQ_MAGNITUDE']

# Visualización de la importancia de las características
plt.figure(figsize=(8, 6))
sns.barplot(x=importances, y=features, palette='Blues_d')
plt.title('Importancia de las Características en el Modelo Random Forest')
plt.xlabel('Importancia')
plt.ylabel('Características')
plt.show()

from sklearn.tree import export_graphviz
from graphviz import Source

# Exportar el árbol como archivo dot
dot_data = export_graphviz(clf.estimators_[0], out_file=None,
                           feature_names=X.columns,
                           class_names=clf.classes_,
                           filled=True, rounded=True,
                           special_characters=True)

# Visualizar el árbol
graph = Source(dot_data)
graph.render("/content/decision_tree", format="png", cleanup=True)  # Guardar como imagen el Modelo de Random Forest
graph.view()

"""CLUSTERING"""

